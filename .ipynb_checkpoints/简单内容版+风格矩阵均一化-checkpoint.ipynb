{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import imageio\n",
    "from nst_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image = imageio.imread(\"images/monet.jpg\")\n",
    "style_image = reshape_and_normalize_image(style_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_S = load_vgg_model(style_image, \"pretrained-model/imagenet-vgg-verydeep-19.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = imageio.imread(\"images/louvre_small.jpg\")\n",
    "content_image = reshape_and_normalize_image(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_C = load_vgg_model(content_image, \"pretrained-model/imagenet-vgg-verydeep-19.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = generate_noise_image(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_G = load_vgg_model(generated_image, \"pretrained-model/imagenet-vgg-verydeep-19.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_content_cost(a_C, a_G):\n",
    "    \"\"\"\n",
    "    计算内容损失\n",
    "    \"\"\"\n",
    "\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    # 将3维转换维2维\n",
    "    a_C_unrolled = tf.transpose(a_C)\n",
    "    a_G_unrolled = tf.transpose(a_G)\n",
    "    \n",
    "    # 利用前面的公式计算内容损失\n",
    "    J_content = (1/ (4* n_H * n_W * n_C)) * tf.reduce_sum(tf.pow((a_G_unrolled - a_C_unrolled), 2))\n",
    "\n",
    "    return J_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(7671.205, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "a_C = model_C['conv4_2']\n",
    "a_G = model_G['conv4_2']\n",
    "\n",
    "J_content = compute_content_cost(a_C, a_G)\n",
    "\n",
    "print(J_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算风格矩阵\n",
    "\n",
    "def gram_matrix(A):\n",
    "\n",
    "    GA = tf.matmul(A, tf.transpose(A))\n",
    "    \n",
    "    return GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算某一层的风格损失\n",
    "def compute_layer_style_cost(a_S, a_G):\n",
    "\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    # 改变激活值的维度\n",
    "    a_S = tf.transpose(tf.reshape(a_S, [n_H*n_W, n_C]))\n",
    "    a_G = tf.transpose(tf.reshape(a_G, [n_H*n_W, n_C]))\n",
    "\n",
    "    # 计算风格矩阵\n",
    "    GS = gram_matrix(a_S)\n",
    "    GG = gram_matrix(a_G)\n",
    "\n",
    "    # 计算风格损失\n",
    "    J_style_layer = (1./(4 * n_C**2 * (n_H*n_W)**2)) * tf.reduce_sum(tf.pow((GS - GG), 2))\n",
    "    \n",
    "    return J_style_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.2),\n",
    "    ('conv2_1', 0.2),\n",
    "    ('conv3_1', 0.2),\n",
    "    ('conv4_1', 0.2),\n",
    "    ('conv5_1', 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我自己加的一个均一化函数\n",
    "def normalize(data):\n",
    "    mean=tf.reduce_mean(data)\n",
    "    mx=tf.reduce_max(data)\n",
    "    mn=tf.reduce_min(data)\n",
    "    \n",
    "    return (data-mean)/(mx-mn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_style_cost(model_S, model_G, STYLE_LAYERS):\n",
    "    \"\"\"\n",
    "    就是多个神经网络层的风格损失\n",
    "    \n",
    "    参数:\n",
    "    model -- tensorflow模型，在这里是VGG模型\n",
    "    STYLE_LAYERS -- 风格权重\n",
    "    \"\"\"\n",
    "    \n",
    "    J_style = tf.constant(0.0, dtype=tf.float32)\n",
    "    \n",
    "\n",
    "    for layer_name, coeff in STYLE_LAYERS:\n",
    "\n",
    "\n",
    "        # 执行这层神经网络，将这层的激活值存到a_S中\n",
    "        a_S = model_S[layer_name]\n",
    "        \n",
    "        a_G = model_G[layer_name]\n",
    "        \n",
    "        a_S_n=normalize(a_S)\n",
    "        a_G_n=normalize(a_G)\n",
    "        \n",
    "        # 计算这一层的风格损失\n",
    "        J_style_layer = compute_layer_style_cost(a_S_n, a_G_n)\n",
    "\n",
    "        # 整合每一层的风格损失\n",
    "        J_style += coeff * J_style_layer\n",
    "\n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.411967e-07, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "J_style = compute_style_cost(model_S, model_G, STYLE_LAYERS)\n",
    "print(J_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整的损失函数\n",
    "def total_cost(J_content, J_style, alpha = 1, beta = 2e+11):\n",
    "    \n",
    "    J = alpha * J_content + beta * J_style\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(115910.54, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "J = total_cost(J_content, J_style, alpha = 1, beta = 2e+11)\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nn(model_C, model_S, generated_image, STYLE_LAYERS, num_epochs = 200):\n",
    "    \n",
    "    for epoch in range(num_epochs+1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            model_G = load_vgg_model(generated_image, \"pretrained-model/imagenet-vgg-verydeep-19.mat\")\n",
    "            J_content = compute_content_cost(model_C['conv4_2'], model_G['conv4_2'])\n",
    "            J_style = compute_style_cost(model_S, model_G, STYLE_LAYERS)\n",
    "            J = total_cost(J_content, J_style, alpha = 1, beta = 2e+11)\n",
    "            \n",
    "        grads = tape.gradient(J,[model_G['input']])\n",
    "        optimizer.apply_gradients(zip(grads,[model_G['input']]))\n",
    "        generated_image = model_G['input']\n",
    "        \n",
    "        if epoch%20 == 0:\n",
    "            tf.print('After epoch:', epoch)\n",
    "            tf.print('total cost = ', J)\n",
    "            tf.print('content cost = ', J_content*1)\n",
    "            tf.print('style cost = ', J_style*2e+11)\n",
    "            \n",
    "            save_image(\"output/\" + str(epoch) + \".png\", generated_image)\n",
    "            \n",
    "    # 经过上面的训练后，将最终的生成图片保存起来。\n",
    "    save_image('output/generated_image.jpg', generated_image)\n",
    "    \n",
    "    return generated_image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch: 0\n",
      "total cost =  115910.539\n",
      "content cost =  7671.20508\n",
      "style cost =  108239.336\n",
      "After epoch: 20\n",
      "total cost =  45191.3828\n",
      "content cost =  7487.06\n",
      "style cost =  37704.3242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 300, 400, 3) dtype=float32, numpy=\n",
       "array([[[[-46.54687   , -14.251657  ,  10.505059  ],\n",
       "         [-28.419853  , -12.724619  ,   1.6518912 ],\n",
       "         [-44.472576  , -14.788467  ,   7.0801272 ],\n",
       "         ...,\n",
       "         [-30.25907   ,  -1.5379884 , -34.888832  ],\n",
       "         [-38.846283  , -18.535849  , -30.539268  ],\n",
       "         [-38.392197  ,  -6.954854  ,  -7.6627355 ]],\n",
       "\n",
       "        [[-12.997549  , -18.848644  , -22.0408    ],\n",
       "         [-34.579197  , -37.296764  , -10.941256  ],\n",
       "         [-28.486677  , -22.586496  ,   5.022859  ],\n",
       "         ...,\n",
       "         [-14.788296  , -19.345076  , -10.3291    ],\n",
       "         [-32.38979   ,  -7.7613444 , -18.652178  ],\n",
       "         [-25.397675  ,   2.7211418 , -23.743399  ]],\n",
       "\n",
       "        [[-42.048943  , -28.77278   , -17.590612  ],\n",
       "         [-42.43826   , -24.82773   ,   0.4477296 ],\n",
       "         [-31.090736  , -24.140501  ,   6.21704   ],\n",
       "         ...,\n",
       "         [-23.098715  ,  -5.9190526 , -26.699     ],\n",
       "         [-30.139278  , -17.209526  , -26.68078   ],\n",
       "         [-25.693018  , -10.357155  , -17.288092  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -2.4346774 , -32.425423  , -20.959097  ],\n",
       "         [  0.5396135 , -32.898582  , -39.314762  ],\n",
       "         [ -3.5499825 , -28.892477  , -54.800117  ],\n",
       "         ...,\n",
       "         [-16.091578  , -32.79668   , -35.9931    ],\n",
       "         [-14.918643  , -14.0399475 , -47.39078   ],\n",
       "         [ -5.3971243 , -31.358786  , -29.101694  ]],\n",
       "\n",
       "        [[ -0.6981205 , -21.01474   ,   0.51824385],\n",
       "         [ -5.0301313 , -33.197147  , -21.58262   ],\n",
       "         [  7.770178  , -38.026104  , -28.286316  ],\n",
       "         ...,\n",
       "         [-43.322506  , -43.798164  , -52.926212  ],\n",
       "         [-34.425148  , -36.272984  , -53.998257  ],\n",
       "         [-36.951996  , -23.361664  , -27.68988   ]],\n",
       "\n",
       "        [[  2.479761  , -26.271463  ,  12.933627  ],\n",
       "         [ 17.043045  , -32.499134  ,   1.4954351 ],\n",
       "         [  1.2700198 , -35.528645  , -21.675995  ],\n",
       "         ...,\n",
       "         [-42.255386  , -54.418667  , -31.56685   ],\n",
       "         [-54.270546  , -42.71068   , -37.714565  ],\n",
       "         [-41.906776  , -46.570145  ,  -2.5679917 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn(model_C, model_S, generated_image, STYLE_LAYERS, num_epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
